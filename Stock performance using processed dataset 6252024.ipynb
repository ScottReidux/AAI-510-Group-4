{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The stock's performance using processed data\n",
    "#  Plot actual and predicted values for each stock \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the list of stock tickers and corresponding file paths\n",
    "tickers = ['NVDA', 'MSFT', 'AMD', 'AAPL', 'TSLA']\n",
    "file_paths = {\n",
    "    'NVDA': r'C:\\USD\\Machine Learning - Fundamentals AAI 510\\Final Team Project\\processed\\processed\\processed_nvda.us.txt',\n",
    "    'MSFT': r'C:\\USD\\Machine Learning - Fundamentals AAI 510\\Final Team Project\\processed\\processed\\processed_msft.us.txt',\n",
    "    'AMD': r'C:\\USD\\Machine Learning - Fundamentals AAI 510\\Final Team Project\\processed\\processed\\processed_amd.us.txt',\n",
    "    'AAPL': r'C:\\USD\\Machine Learning - Fundamentals AAI 510\\Final Team Project\\processed\\processed\\processed_aapl.us.txt',\n",
    "    'AMZN': r'C:\\USD\\Machine Learning - Fundamentals AAI 510\\Final Team Project\\processed\\processed\\processed_amzn.us.txt',\n",
    "    'TSLA': r'C:\\USD\\Machine Learning - Fundamentals AAI 510\\Final Team Project\\processed\\processed\\processed_tsla.us.txt'\n",
    "}\n",
    "\n",
    "# Define the date range\n",
    "start_date = '2014-01-01'\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Function to create lag features\n",
    "def create_lag_features(df, lags):\n",
    "    for lag in range(1, lags + 1):\n",
    "        df[f'lag_{lag}'] = df['Close'].shift(lag)\n",
    "    df['rolling_mean_5'] = df['Close'].rolling(window=5).mean()\n",
    "    df['rolling_std_5'] = df['Close'].rolling(window=5).std()\n",
    "    df['rolling_mean_10'] = df['Close'].rolling(window=10).mean()\n",
    "    df['rolling_std_10'] = df['Close'].rolling(window=10).std()\n",
    "    df['rolling_mean_20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['rolling_std_20'] = df['Close'].rolling(window=20).std()\n",
    "    df['momentum'] = df['Close'] - df['Close'].shift(4)\n",
    "    return df.dropna()\n",
    "\n",
    "# Function to normalize data\n",
    "def normalize_data(df):\n",
    "    return (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "# Function to fit and predict using Random Forest and XGBoost\n",
    "def fit_and_predict(df, ticker):\n",
    "    # Create lag features\n",
    "    df = create_lag_features(df, 7)\n",
    "    \n",
    "    # Define features and target\n",
    "    features = [f'lag_{i}' for i in range(1, 8)] + ['rolling_mean_5', 'rolling_std_5', 'rolling_mean_10', 'rolling_std_10', 'rolling_mean_20', 'rolling_std_20', 'momentum']\n",
    "    X = df[features]\n",
    "    y = df['Close']\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n",
    "    \n",
    "    # Hyperparameter tuning for Random Forest\n",
    "    rf_params = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2],\n",
    "        'bootstrap': [True, False]\n",
    "    }\n",
    "    rf_model = RandomForestRegressor(random_state=42)\n",
    "    rf_random = RandomizedSearchCV(rf_model, rf_params, n_iter=20, cv=3, n_jobs=-1, random_state=42, scoring='neg_mean_squared_error')\n",
    "    rf_random.fit(X_train, y_train)\n",
    "    rf_best_model = rf_random.best_estimator_\n",
    "    \n",
    "    # Predict with Random Forest\n",
    "    y_pred_rf = rf_best_model.predict(X_test)\n",
    "    \n",
    "    # Hyperparameter tuning for XGBoost\n",
    "    xgb_params = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [3, 6],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "    xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "    xgb_random = RandomizedSearchCV(xgb_model, xgb_params, n_iter=20, cv=3, n_jobs=-1, random_state=42, scoring='neg_mean_squared_error')\n",
    "    xgb_random.fit(X_train, y_train)\n",
    "    xgb_best_model = xgb_random.best_estimator_\n",
    "    \n",
    "    # Predict with XGBoost\n",
    "    y_pred_xgb = xgb_best_model.predict(X_test)\n",
    "    \n",
    "    # Normalize the data for comparison\n",
    "    df['Close'] = normalize_data(df['Close'])\n",
    "    y_test = normalize_data(y_test)\n",
    "    y_pred_rf = normalize_data(pd.Series(y_pred_rf, index=y_test.index))\n",
    "    y_pred_xgb = normalize_data(pd.Series(y_pred_xgb, index=y_test.index))\n",
    "    \n",
    "    # Plot actual vs predicted\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df.index[-len(y_test):], y_test, label='Actual', marker='o')\n",
    "    plt.plot(df.index[-len(y_test):], y_pred_rf, label='Random Forest Predicted', linestyle='--')\n",
    "    plt.plot(df.index[-len(y_test):], y_pred_xgb, label='XGBoost Predicted', linestyle='--')\n",
    "    plt.title(f'{ticker} Stock Prediction')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Normalized Close Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(f'{ticker} Random Forest MSE: {mean_squared_error(y_test, y_pred_rf):.4f}')\n",
    "    print(f'{ticker} XGBoost MSE: {mean_squared_error(y_test, y_pred_xgb):.4f}')\n",
    "    print(f'{ticker} Random Forest MAE: {mean_absolute_error(y_test, y_pred_rf):.4f}')\n",
    "    print(f'{ticker} XGBoost MAE: {mean_absolute_error(y_test, y_pred_xgb):.4f}')\n",
    "    print(f'{ticker} Random Forest R²: {r2_score(y_test, y_pred_rf):.4f}')\n",
    "    print(f'{ticker} XGBoost R²: {r2_score(y_test, y_pred_xgb):.4f}')\n",
    "\n",
    "# Load and process each stock data\n",
    "for ticker in tickers:\n",
    "    print(f'\\nProcessing {ticker}...\\n')\n",
    "    file_path = file_paths[ticker]\n",
    "    df_ticker = pd.read_csv(file_path)\n",
    "    df_ticker['Date'] = pd.to_datetime(df_ticker['Date'])\n",
    "    df_ticker.set_index('Date', inplace=True)\n",
    "    fit_and_predict(df_ticker, ticker)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
